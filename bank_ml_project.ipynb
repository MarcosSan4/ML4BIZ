{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5a4ad7",
   "metadata": {},
   "source": [
    "# Bank Marketing ML Project\n",
    "\n",
    "## Goal: Predict whether a customer will subscribe to a term deposit (binary classification)\n",
    "\n",
    "**Dataset**: `bank_24.pkl`  \n",
    "**Target Variable**: `deposit` (yes/no)  \n",
    "**Records**: 11,000 samples, 17 features\n",
    "\n",
    "---\n",
    "\n",
    "## Machine Learning Workflow Steps:\n",
    "1. **Data Loading & Inspection** - Load pickle file and understand the data\n",
    "2. **Exploratory Data Analysis (EDA)** - Visualize distributions, correlations, class balance\n",
    "3. **Data Preprocessing** - Handle missing values, encode categorical variables, scale features\n",
    "4. **Train/Test Split** - Split data for model validation\n",
    "5. **Model Training** - Train multiple algorithms (Logistic Regression, Decision Tree, Random Forest, KNN)\n",
    "6. **Model Evaluation** - Compare models using accuracy, precision, recall, F1-score, ROC-AUC\n",
    "7. **Hyperparameter Tuning** - Optimize the best model\n",
    "8. **Final Model** - Save the best model for production\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48310e0f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d14b1e",
   "metadata": {},
   "source": [
    "## 2. Load Dataset from Pickle File\n",
    "\n",
    "Pickle files store Python objects in binary format. We'll load the dataset and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('bank_24.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "print(f\"✅ Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape} (rows, columns)\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7b894",
   "metadata": {},
   "source": [
    "## 3. Data Inspection & Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's understand our data better before building models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Dataset info\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
    "print(missing_df[missing_df['Missing'] > 0])\n",
    "\n",
    "# Note: 'marital' has 447 missing values (4.07%)\n",
    "print(f\"\\n⚠️ Found {missing_df[missing_df['Missing'] > 0].shape[0]} columns with missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical features\n",
    "print(\"Numerical Features Summary:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d22f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution (Class balance check)\n",
    "print(\"Target Variable Distribution (deposit):\")\n",
    "print(df['deposit'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['deposit'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "df['deposit'].value_counts().plot(kind='bar', ax=ax[0], color=['#FF6B6B', '#4ECDC4'])\n",
    "ax[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('Deposit')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "df['deposit'].value_counts(normalize=True).plot(kind='pie', ax=ax[1], autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4'])\n",
    "ax[1].set_title('Class Distribution (%)', fontsize=14, fontweight='bold')\n",
    "ax[1].set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "if df['deposit'].value_counts().min() / df['deposit'].value_counts().max() < 0.3:\n",
    "    print(\"\\n⚠️ Class imbalance detected! Consider using techniques like SMOTE, class weights, or stratified sampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82878367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features distribution\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i < len(axes):\n",
    "        df[col].hist(bins=30, ax=axes[i], edgecolor='black', alpha=0.7)\n",
    "        axes[i].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(len(numerical_cols), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Distribution of Numerical Features', y=1.01, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('deposit')  # Remove target variable\n",
    "\n",
    "print(f\"Categorical Features ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
    "    print(df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e49f2b",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Now we'll prepare the data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb157003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values in 'marital' column\n",
    "# Option 1: Fill with mode (most common value)\n",
    "df['marital'].fillna(df['marital'].mode()[0], inplace=True)\n",
    "\n",
    "# Option 2 (alternative): Drop rows with missing values\n",
    "# df.dropna(inplace=True)\n",
    "\n",
    "print(f\"✅ Missing values handled\")\n",
    "print(f\"Remaining missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d62b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Separate features (X) and target (y)\n",
    "X = df.drop('deposit', axis=1)\n",
    "y = df['deposit']\n",
    "\n",
    "# Encode target variable (yes=1, no=0)\n",
    "y = y.map({'yes': 1, 'no': 0})\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81445fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
